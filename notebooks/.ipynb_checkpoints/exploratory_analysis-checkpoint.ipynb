{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Response Times\n",
    "Looking at spectrograms of different triggers with different response times. My hypothesis is that there is some difference in power depending on how the long it takes for the patient to vocalize a response. This would be related to sort of inherent memory vs. actively searching for the memory.\n",
    "\n",
    "Things to Change: \n",
    "1. Patient dir if you analyze a new patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "import numpy as np\n",
    "import os, csv, json\n",
    "import math\n",
    "import random\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import scipy.io\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# pretty charting\n",
    "import seaborn as sns\n",
    "sns.set_palette('muted')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were  49  number of incorrect events.\n",
      "The list of incorrect probe words: \n",
      "{\"[u'PANTS']\": 7, \"[u'JUICE']\": 8, \"[u'BRICK']\": 12, \"[u'CLOCK']\": 13, \"[u'GLASS']\": 9}\n",
      "\n",
      "This is the length of the events struct with only correct responses:  1431\n",
      "There are  96  files inside our directory\n",
      "This should match the number of channels.\n"
     ]
    }
   ],
   "source": [
    "######## Get list of files (.mat) we want to work with ########\n",
    "filedir = '../condensed_data/freq_probeTovocal_binned/'\n",
    "files = []\n",
    "\n",
    "for file in os.listdir(filedir):\n",
    "    if file.endswith('.mat'):\n",
    "        files.append(file)\n",
    "\n",
    "######## Load in EVENTS struct to find correct events\n",
    "eventsDir = '../NIH034/behavioral/paRemap/' + 'events.mat'\n",
    "\n",
    "events = scipy.io.loadmat(eventsDir)\n",
    "events = events['events']\n",
    "\n",
    "# print number of incorrect events and which words they belonged to\n",
    "incorrectIndices = events['isCorrect'] == 0\n",
    "incorrectEvents = events[incorrectIndices]\n",
    "incorrectWords = []\n",
    "wordList = {}\n",
    "for i in range(0, len(incorrectEvents)):\n",
    "    incorrectWords.append(incorrectEvents['probeWord'][i][0])\n",
    "\n",
    "for word in np.unique(incorrectEvents['probeWord']):\n",
    "    wordList[str(word)] = sum(incorrectWords == word)\n",
    "    \n",
    "print \"There were \",len(incorrectEvents), \" number of incorrect events.\"\n",
    "print \"The list of incorrect probe words: \\n\", wordList\n",
    "# \n",
    "# get only correct events\n",
    "correctIndices = events['isCorrect'] == 1\n",
    "events = events[correctIndices]\n",
    "\n",
    "print \"\\nThis is the length of the events struct with only correct responses: \", len(events)\n",
    "print \"There are \", len(files), \" files inside our directory\"\n",
    "print \"This should match the number of channels.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extract Important Events Information\n",
    "Response Times, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n",
      "[('experiment', 'O'), ('subject', 'O'), ('sessionName', 'O'), ('sessionNum', 'O'), ('type', 'O'), ('msoffset', 'O'), ('mstime', 'O'), ('probeWord', 'O'), ('targetWord', 'O'), ('isCorrect', 'O'), ('blocknumber', 'O'), ('miniblocknumber', 'O'), ('matchOnTime', 'O'), ('probeOffTime', 'O'), ('fixationOnTime', 'O'), ('fixationOffTime', 'O'), ('responseTime', 'O'), ('vocalizedWord', 'O'), ('eegfile', 'O'), ('eegoffset', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# convert responsetime into a list\n",
    "responseTimes = []\n",
    "for i in range(0, len(events)):\n",
    "    responseTimes.append(events['responseTime'][0][0][0])\n",
    "responseTimes = np.array(responseTimes)\n",
    "    \n",
    "# create a dictionary of response times for each probe word\n",
    "wordResponseTimes = {}\n",
    "for word in np.unique(incorrectEvents['probeWord']):\n",
    "    wordIndices = events['probeWord'] == word\n",
    "    mask = np.where(wordIndices==True)[0]\n",
    "    wordResponseTimes[str(word[0])] = responseTimes[mask]\n",
    "print events.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final feature dictionary will have features from the \n",
      "following channels:  ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96']\n",
      "Each channel has these features:  ['JUICE_GLASS', 'BRICK_JUICE', 'CLOCK_GLASS', 'PANTS_GLASS', 'GLASS_JUICE', 'BRICK_CLOCK', 'GLASS_PANTS', 'PANTS_BRICK', 'GLASS_CLOCK', 'JUICE_BRICK', 'BRICK_PANTS', 'CLOCK_BRICK']\n",
      "With shape of:  (7,)\n"
     ]
    }
   ],
   "source": [
    "################## LOOPING THROUGH EACH CHANNEL ##################\n",
    "feature_dict = {} # the dict to hold the feature matrix for each channel\n",
    "\n",
    "for f in range(0, len(files)):\n",
    "    #################### Set up data from the channel's mat file ####################\n",
    "    # Go through each .mat file\n",
    "    mat_file = filedir + files[f]\n",
    "\n",
    "    data = scipy.io.loadmat(mat_file)\n",
    "    data = data['data']\n",
    "\n",
    "\n",
    "    ## 01: reformat unique trigger types\n",
    "    uniqueTrigTypes = data['uniqueTrigType'][0][0][0]\n",
    "    buff = []\n",
    "    for trig in uniqueTrigTypes:\n",
    "        buff.append(str(trig[0]))\n",
    "    uniqueTrigTypes = buff\n",
    "\n",
    "    ## 02: reformat trigger types\n",
    "    trigTypes = data['trigType'][0][0][0]\n",
    "    buff = []\n",
    "    for trig in trigTypes:\n",
    "        buff.append(str(trig[0]))\n",
    "    trigTypes = buff\n",
    "\n",
    "    ## 03: get channel number\n",
    "    chanNum = data['chanNum'][0][0][0][0]\n",
    "\n",
    "    ## 04: get channel string\n",
    "    chanStr = data['chanStr'][0][0][0]\n",
    "\n",
    "    ## 05: get power matrix Z is a #events X #freq. bands\n",
    "    matrix = data['powerMatZ'][0][0]\n",
    "\n",
    "    ## 06: get freq band ticks and ylabels\n",
    "    freqBandYtick = data['freqBandYtick'][0][0][0]\n",
    "    freqBandYlabel = data['freqBandYlabel'][0][0][0]\n",
    "    buff = []\n",
    "    for freq in freqBandYlabel:\n",
    "        buff.append(str(freq[0]))\n",
    "    freqBandYlabel = buff\n",
    "\n",
    "    #################### Getting those events and the corresonding averaged powermat  ####################\n",
    "    ## Get events of interest\n",
    "    TRIGGER_TYPES = uniqueTrigTypes\n",
    "    probeWords = events['probeWord']\n",
    "    targetWords = events['targetWord']\n",
    "\n",
    "    # number of frequency bins\n",
    "    num_freqs = len(freqBandYtick) - 1\n",
    "    # total number of \"data centers\"\n",
    "#     num_features = len(TRIGGER_TYPES)*len(tempTargets)\n",
    "    features = {}\n",
    "    \n",
    "    for i in range(0,len(TRIGGER_TYPES)): # LOOP THRU EACH PROBEWORD\n",
    "        current_trig = TRIGGER_TYPES[i]\n",
    "\n",
    "        ## 01: get indices of the current trigger and get those events\n",
    "        tempInd = events['probeWord'] == current_trig\n",
    "        tempEvents = events[tempInd]\n",
    "        tempTargets = np.unique(tempEvents['targetWord'])\n",
    "    \n",
    "        ## 02: go through each target word for this probeword\n",
    "        for j in range(0, len(tempTargets)):\n",
    "            targetWord = tempTargets[j][0] # set target word\n",
    "    \n",
    "            # get the indices of the events we want probe/target match\n",
    "            eventInd = events['probeWord'] == current_trig\n",
    "            eventInd2 = events['targetWord'] == targetWord\n",
    "            eventInd = np.array([any(tup) for tup in zip(eventInd, eventInd2)])\n",
    "\n",
    "            # get the matrix we want and average across all events \n",
    "            thisMat = np.mean(matrix[eventInd,:], axis=0)\n",
    "            # -> a 7x1 vector that represents this match for this channel \n",
    "            \n",
    "            feature_key = str(current_trig) + '_' + str(targetWord)\n",
    "            \n",
    "            features[feature_key] = thisMat\n",
    "            # clear vars\n",
    "            eventInd2 = 0\n",
    "    \n",
    "    # turn features into np array and append to a dict of the features\n",
    "#     features = np.array(features)\n",
    "    feature_dict[str(f+1)] = features\n",
    "\n",
    "print \"The final feature dictionary will have features from the \"\n",
    "print \"following channels: \", sorted(feature_dict.keys())\n",
    "print \"Each channel has these features: \", feature_dict['2'].keys()\n",
    "print \"With shape of: \", feature_dict['2']['JUICE_GLASS'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JUICE_GLASS', 'BRICK_JUICE', 'CLOCK_GLASS', 'PANTS_GLASS', 'GLASS_JUICE', 'BRICK_CLOCK', 'GLASS_PANTS', 'PANTS_BRICK', 'GLASS_CLOCK', 'JUICE_BRICK', 'BRICK_PANTS', 'CLOCK_BRICK']\n"
     ]
    }
   ],
   "source": [
    "## Reorganize data based on response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
