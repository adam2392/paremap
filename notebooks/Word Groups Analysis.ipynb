{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Distances Between Various Groups of Word Pairs\n",
    "By: Adam Li\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "import numpy as np\n",
    "import os, csv, json\n",
    "import math\n",
    "import random\n",
    "\n",
    "import itertools\n",
    "import matplotlib\n",
    "from matplotlib import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "# pretty charting\n",
    "import seaborn as sns\n",
    "sns.set_palette('muted')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were  49  number of incorrect events.\n",
      "The list of incorrect probe words: \n",
      "{\"[u'PANTS']\": 7, \"[u'JUICE']\": 8, \"[u'BRICK']\": 12, \"[u'CLOCK']\": 13, \"[u'GLASS']\": 9}\n",
      "\n",
      "This is the length of the events struct with only correct responses:  1431\n",
      "The group of word pairings are:  ['BRICK_CLOCK', 'BRICK_JUICE', 'BRICK_PANTS', 'CLOCK_BRICK', 'CLOCK_GLASS', 'GLASS_CLOCK', 'GLASS_JUICE', 'GLASS_PANTS', 'JUICE_BRICK', 'JUICE_GLASS', 'PANTS_BRICK', 'PANTS_GLASS']\n"
     ]
    }
   ],
   "source": [
    "######## Get list of files (.mat) we want to work with ########\n",
    "filedir = '../condensed_data/groups/'\n",
    "files = []\n",
    "groups = []\n",
    "\n",
    "# get all unique word match pairs and store in 'groups' list\n",
    "for file in os.listdir(filedir):\n",
    "    groups.append(file)\n",
    "    if file.endswith('.mat'):\n",
    "        files.append(file)\n",
    "\n",
    "######## Load in EVENTS struct to find correct events\n",
    "eventsDir = '../NIH034/behavioral/paRemap/' + 'events.mat'\n",
    "\n",
    "events = scipy.io.loadmat(eventsDir)\n",
    "events = events['events']\n",
    "\n",
    "# print number of incorrect events and which words they belonged to\n",
    "incorrectIndices = events['isCorrect'] == 0\n",
    "incorrectEvents = events[incorrectIndices]\n",
    "incorrectWords = []\n",
    "wordList = {}\n",
    "for i in range(0, len(incorrectEvents)):\n",
    "    incorrectWords.append(incorrectEvents['probeWord'][i][0])\n",
    "\n",
    "for word in np.unique(incorrectEvents['probeWord']):\n",
    "    wordList[str(word)] = sum(incorrectWords == word)\n",
    "    \n",
    "print \"There were \",len(incorrectEvents), \" number of incorrect events.\"\n",
    "print \"The list of incorrect probe words: \\n\", wordList\n",
    "# \n",
    "# get only correct events\n",
    "correctIndices = events['isCorrect'] == 1\n",
    "events = events[correctIndices]\n",
    "\n",
    "print \"\\nThis is the length of the events struct with only correct responses: \", len(events)\n",
    "print \"The group of word pairings are: \", groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For different words:\n",
      "('BRICK_CLOCK', 'GLASS_JUICE')\n",
      "('CLOCK_BRICK', 'GLASS_PANTS')\n",
      "('CLOCK_BRICK', 'JUICE_GLASS')\n",
      "('CLOCK_BRICK', 'PANTS_GLASS')\n",
      "('BRICK_JUICE', 'CLOCK_GLASS')\n",
      "('JUICE_BRICK', 'GLASS_CLOCK')\n",
      "('JUICE_BRICK', 'GLASS_PANTS')\n",
      "('JUICE_BRICK', 'PANTS_GLASS')\n",
      "('BRICK_PANTS', 'CLOCK_GLASS')\n",
      "('PANTS_BRICK', 'GLASS_CLOCK')\n",
      "('BRICK_PANTS', 'GLASS_JUICE')\n",
      "('PANTS_BRICK', 'JUICE_GLASS')\n",
      "('CLOCK_BRICK', 'GLASS_JUICE')\n",
      "('BRICK_CLOCK', 'GLASS_PANTS')\n",
      "('BRICK_CLOCK', 'JUICE_GLASS')\n",
      "('BRICK_CLOCK', 'PANTS_GLASS')\n",
      "('GLASS_CLOCK', 'BRICK_JUICE')\n",
      "('CLOCK_GLASS', 'JUICE_BRICK')\n",
      "('CLOCK_GLASS', 'PANTS_BRICK')\n",
      "('GLASS_CLOCK', 'BRICK_PANTS')\n",
      "('GLASS_JUICE', 'PANTS_BRICK')\n",
      "('PANTS_GLASS', 'BRICK_JUICE')\n",
      "('BRICK_JUICE', 'GLASS_PANTS')\n",
      "('JUICE_GLASS', 'BRICK_PANTS')\n",
      "For reverse words:\n",
      "('JUICE_BRICK', 'BRICK_JUICE')\n",
      "('BRICK_PANTS', 'PANTS_BRICK')\n",
      "('CLOCK_BRICK', 'BRICK_CLOCK')\n",
      "('GLASS_CLOCK', 'CLOCK_GLASS')\n",
      "('PANTS_GLASS', 'GLASS_PANTS')\n",
      "('JUICE_GLASS', 'GLASS_JUICE')\n",
      "For probe words:\n",
      "('BRICK_CLOCK', 'BRICK_PANTS')\n",
      "('BRICK_JUICE', 'BRICK_CLOCK')\n",
      "('BRICK_JUICE', 'BRICK_PANTS')\n",
      "('JUICE_BRICK', 'JUICE_GLASS')\n",
      "('PANTS_BRICK', 'PANTS_GLASS')\n",
      "('CLOCK_BRICK', 'CLOCK_GLASS')\n",
      "('GLASS_CLOCK', 'GLASS_PANTS')\n",
      "('GLASS_CLOCK', 'GLASS_JUICE')\n",
      "('GLASS_PANTS', 'GLASS_JUICE')\n",
      "For target words:\n",
      "('BRICK_CLOCK', 'GLASS_JUICE')\n",
      "('CLOCK_BRICK', 'GLASS_PANTS')\n",
      "('CLOCK_BRICK', 'JUICE_GLASS')\n",
      "('CLOCK_BRICK', 'PANTS_GLASS')\n",
      "('BRICK_JUICE', 'CLOCK_GLASS')\n",
      "('JUICE_BRICK', 'GLASS_CLOCK')\n",
      "('JUICE_BRICK', 'GLASS_PANTS')\n",
      "('JUICE_BRICK', 'PANTS_GLASS')\n",
      "('BRICK_PANTS', 'CLOCK_GLASS')\n",
      "('PANTS_BRICK', 'GLASS_CLOCK')\n",
      "('BRICK_PANTS', 'GLASS_JUICE')\n",
      "('PANTS_BRICK', 'JUICE_GLASS')\n",
      "('CLOCK_BRICK', 'GLASS_JUICE')\n",
      "('BRICK_CLOCK', 'GLASS_PANTS')\n",
      "('BRICK_CLOCK', 'JUICE_GLASS')\n",
      "('BRICK_CLOCK', 'PANTS_GLASS')\n",
      "('GLASS_CLOCK', 'BRICK_JUICE')\n",
      "('CLOCK_GLASS', 'JUICE_BRICK')\n",
      "('CLOCK_GLASS', 'PANTS_BRICK')\n",
      "('GLASS_CLOCK', 'BRICK_PANTS')\n",
      "('GLASS_JUICE', 'PANTS_BRICK')\n",
      "('PANTS_GLASS', 'BRICK_JUICE')\n",
      "('BRICK_JUICE', 'GLASS_PANTS')\n",
      "('JUICE_GLASS', 'BRICK_PANTS')\n"
     ]
    }
   ],
   "source": [
    "diff_words_groups = []\n",
    "reverse_words_groups = []\n",
    "probe_words_groups = ()\n",
    "target_words_groups = []\n",
    "\n",
    "def inGroup(group, names):\n",
    "    for i in range(0, len(group)):\n",
    "        if cmpT(group[i],names):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def cmpT(t1, t2): \n",
    "    return sorted(t1) == sorted(t2)\n",
    "\n",
    "# Create different groups\n",
    "for pair_first in groups:\n",
    "    # split words by delimiter '_' to determine groups\n",
    "    firstpair = pair_first.split('_')\n",
    "    \n",
    "    for pair_second in groups:\n",
    "        secondpair = pair_second.split('_')\n",
    "\n",
    "        # make directory names for each word pair\n",
    "        firstname = '_'.join(firstpair)\n",
    "        secondname = '_'.join(secondpair)\n",
    "        names = (firstname, secondname)\n",
    "        \n",
    "        ## 01: Different words group\n",
    "        if not any(x in secondpair for x in firstpair) and not inGroup(diff_words_groups,names):\n",
    "            diff_words_groups += (names,)\n",
    "                \n",
    "        ## 02: Probe Word Overlap Group\n",
    "        if firstpair[0] == secondpair[0] and firstpair[1] != secondpair[1] and not inGroup(probe_words_groups,names):\n",
    "            probe_words_groups += (names,)\n",
    "        \n",
    "        ## 03: Target Word Overlap Group\n",
    "        if firstpair[1] == secondpair[1] and firstpair[0] != secondpair[0] and not inGroup(target_words_groups,names):\n",
    "            target_words_groups += (names,)\n",
    "            \n",
    "        ## 04: Reverse words Group\n",
    "        reverse_firstpair = firstpair\n",
    "        reverse_firstpair.reverse()\n",
    "        if '_'.join(reverse_firstpair) == secondname and not inGroup(reverse_words_groups,names):\n",
    "            reverse_words_groups += (names,)\n",
    "\n",
    "## printing \n",
    "print \"For different words:\"\n",
    "for i in range(0, len(diff_words_groups)):\n",
    "    print diff_words_groups[i]\n",
    "    \n",
    "print \"For reverse words:\"\n",
    "for i in range(0, len(reverse_words_groups)):\n",
    "    print reverse_words_groups[i]\n",
    "    \n",
    "print \"For probe words:\"\n",
    "for i in range(0, len(probe_words_groups)):\n",
    "    print probe_words_groups[i]\n",
    "    \n",
    "print \"For target words:\"\n",
    "for i in range(0, len(diff_words_groups)):\n",
    "    print diff_words_groups[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next:\n",
    "Now we have lists of combinations of word pairs that we want to compare for each group. Hypothetically, we would assume that the \"different word pairs\" have distances farthest away and the reversed words, have distances closer, and probe and target are also closer. \n",
    "\n",
    "Next, using ANOVA to perform a cutoff on channels and only taking the delta, theta and high gamma frequencies, we want to uncover this result.\n",
    "\n",
    "1. Load Data\n",
    "2. Extract Features\n",
    "3. Plot Distance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Word Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../condensed_data/groups/BRICK_CLOCK\n",
      "96\n",
      "['10_G10-global_groupData.mat', '11_G11-global_groupData.mat', '12_G12-global_groupData.mat', '13_G13-global_groupData.mat', '14_G14-global_groupData.mat', '15_G15-global_groupData.mat', '16_G16-global_groupData.mat', '17_G17-global_groupData.mat', '18_G18-global_groupData.mat', '19_G19-global_groupData.mat', '1_G1-global_groupData.mat', '20_G20-global_groupData.mat', '21_G21-global_groupData.mat', '22_G22-global_groupData.mat', '23_G23-global_groupData.mat', '24_G24-global_groupData.mat', '25_G25-global_groupData.mat', '26_G26-global_groupData.mat', '27_G27-global_groupData.mat', '28_G28-global_groupData.mat', '29_G29-global_groupData.mat', '2_G2-global_groupData.mat', '30_G30-global_groupData.mat', '31_G31-global_groupData.mat', '32_G32-global_groupData.mat', '33_TT1-global_groupData.mat', '34_TT2-global_groupData.mat', '35_TT3-global_groupData.mat', '36_TT4-global_groupData.mat', '37_TT5-global_groupData.mat', '38_TT6-global_groupData.mat', '39_OF1-global_groupData.mat', '3_G3-global_groupData.mat', '40_OF2-global_groupData.mat', '41_OF3-global_groupData.mat', '42_OF4-global_groupData.mat', '43_AST1-global_groupData.mat', '44_AST2-global_groupData.mat', '45_AST3-global_groupData.mat', '46_AST4-global_groupData.mat', '47_MST1-global_groupData.mat', '48_MST2-global_groupData.mat', '49_MST3-global_groupData.mat', '4_G4-global_groupData.mat', '50_MST4-global_groupData.mat', '51_PST1-global_groupData.mat', '52_PST2-global_groupData.mat', '53_PST3-global_groupData.mat', '54_PST4-global_groupData.mat', '55_IO1-global_groupData.mat', '56_IO2-global_groupData.mat', '57_IO3-global_groupData.mat', '58_IO4-global_groupData.mat', '59_IO5-global_groupData.mat', '5_G5-global_groupData.mat', '60_IO6-global_groupData.mat', '61_MO1-global_groupData.mat', '62_MO2-global_groupData.mat', '63_MO3-global_groupData.mat', '64_MO4-global_groupData.mat', '65_MO5-global_groupData.mat', '66_MO6-global_groupData.mat', '67_SO1-global_groupData.mat', '68_SO2-global_groupData.mat', '69_SO3-global_groupData.mat', '6_G6-global_groupData.mat', '70_SO4-global_groupData.mat', '71_SO5-global_groupData.mat', '72_SO6-global_groupData.mat', '73_PP1-global_groupData.mat', '74_PP2-global_groupData.mat', '75_PP3-global_groupData.mat', '76_PP4-global_groupData.mat', '77_PP5-global_groupData.mat', '78_PP6-global_groupData.mat', '79_PP7-global_groupData.mat', '7_G7-global_groupData.mat', '80_PP8-global_groupData.mat', '81_LP1-global_groupData.mat', '82_LP2-global_groupData.mat', '83_LP3-global_groupData.mat', '84_LP4-global_groupData.mat', '85_LP5-global_groupData.mat', '86_LP6-global_groupData.mat', '87_PPST1-global_groupData.mat', '88_PPST2-global_groupData.mat', '89_PPST3-global_groupData.mat', '8_G8-global_groupData.mat', '90_PPST4-global_groupData.mat', '91_LF1-global_groupData.mat', '92_LF2-global_groupData.mat', '93_LF3-global_groupData.mat', '94_LF4-global_groupData.mat', '95_LF5-global_groupData.mat', '96_LF6-global_groupData.mat', '9_G9-global_groupData.mat']\n"
     ]
    }
   ],
   "source": [
    "diff_words_groups\n",
    "\n",
    "for group in diff_words_groups:\n",
    "    for directory in group:\n",
    "        ######## Get list of files (.mat) we want to work with ########\n",
    "        filedir = '../condensed_data/groups/'\n",
    "        filedir = filedir + directory\n",
    "        files = []\n",
    "\n",
    "        for file in os.listdir(filedir):\n",
    "            if file.endswith('.mat'):\n",
    "                files.append(file)\n",
    "        print filedir\n",
    "        print len(files)\n",
    "        print files\n",
    "        break\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
