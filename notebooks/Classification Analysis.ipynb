{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Analysis\n",
    "Take power from each channel and predict brick, glass, clock, or juice probeword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "import numpy as np\n",
    "import os, csv, json\n",
    "import math\n",
    "import random\n",
    "\n",
    "import itertools\n",
    "import matplotlib\n",
    "from matplotlib import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import scipy.io\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import LeaveOneOut\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# pretty charting\n",
    "import seaborn as sns\n",
    "sns.set_palette('muted')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(12345678)  # for reproducibility, set random seed\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"Random Forest\",\n",
    "         \"Linear Discriminant Analysis\", \"Quadratic Discriminant Analysis\",\n",
    "        \"Logistic Regression\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  96  files inside our directory\n",
      "This should match the number of channels.\n",
      "This is the length of the events struct with only correct responses:  1431\n"
     ]
    }
   ],
   "source": [
    "######## Get list of files (.mat) we want to work with ########\n",
    "filedir = '../condensed_data/freq_probeTovocal_binned/'\n",
    "files = []\n",
    "\n",
    "for file in os.listdir(filedir):\n",
    "    if file.endswith('.mat'):\n",
    "        files.append(file)\n",
    "\n",
    "print \"There are \", len(files), \" files inside our directory\"\n",
    "print \"This should match the number of channels.\"\n",
    "\n",
    "######## Load in events struct to find correct events\n",
    "eventsDir = '../NIH034/behavioral/paRemap/' + 'events.mat'\n",
    "\n",
    "events = scipy.io.loadmat(eventsDir)\n",
    "events = events['events']\n",
    "\n",
    "# get correct events\n",
    "correctIndices = events['isCorrect'] == 1\n",
    "events = events[correctIndices]\n",
    "\n",
    "print \"This is the length of the events struct with only correct responses: \", len(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Of ProbeWord Using Match_Features\n",
    "### Extract Fields From Data Struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final feature dictionary will have features from \n",
      "the following channels:  ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96']\n"
     ]
    }
   ],
   "source": [
    "################## LOOPING THROUGH EACH CHANNEL ##################\n",
    "probe_dict = {} # the dict to hold the feature matrix for each channel\n",
    "\n",
    "for f in range(0, len(files)):\n",
    "    #################### Set up data from the channel's mat file ####################\n",
    "    # Go through each .mat file\n",
    "    mat_file = filedir + files[f]\n",
    "\n",
    "    data = scipy.io.loadmat(mat_file)\n",
    "    data = data['data']\n",
    "\n",
    "    ## 01: reformat unique trigger types\n",
    "    uniqueTrigTypes = data['uniqueTrigType'][0][0][0]\n",
    "    buff = []\n",
    "    for trig in uniqueTrigTypes:\n",
    "        buff.append(str(trig[0]))\n",
    "    uniqueTrigTypes = buff\n",
    "\n",
    "    ## 02: reformat trigger types\n",
    "    trigTypes = data['trigType'][0][0][0]\n",
    "    buff = []\n",
    "    for trig in trigTypes:\n",
    "        buff.append(str(trig[0]))\n",
    "    trigTypes = buff\n",
    "\n",
    "    ## 05: get power matrix Z is a #events X #freq. bands\n",
    "    matrix = data['powerMatZ'][0][0]\n",
    "\n",
    "    ########### Getting those events and the corresonding averaged powermat  ################\n",
    "    ## Get events of interest\n",
    "    TRIGGER_TYPES = uniqueTrigTypes\n",
    "    probeWords = events['probeWord']\n",
    "    features = {}\n",
    "    \n",
    "    for i in range(0,len(TRIGGER_TYPES)): # LOOP THRU EACH PROBEWORD\n",
    "        current_trig = TRIGGER_TYPES[i]\n",
    "\n",
    "        ## 01: get indices of the current trigger and get those events\n",
    "        tempInd = events['probeWord'] == current_trig\n",
    "        tempEvents = events[tempInd]\n",
    "        \n",
    "#         # average across events\n",
    "#         thisMat = np.mean(matrix[tempInd,:,], axis=0)\n",
    "        thisMat = matrix[tempInd,:]\n",
    "        features[current_trig] = thisMat\n",
    "        \n",
    "    probe_dict[str(f+1)] = features\n",
    "\n",
    "print \"The final feature dictionary will have features from \"\n",
    "print \"the following channels: \", sorted(probe_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dictionary of All Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRICK\n",
      "(358, 7)\n",
      "CLOCK\n",
      "(227, 7)\n",
      "GLASS\n",
      "(361, 7)\n",
      "JUICE\n",
      "(242, 7)\n",
      "PANTS\n",
      "(243, 7)\n",
      "1431\n"
     ]
    }
   ],
   "source": [
    "summ = 0\n",
    "for key in sorted(probe_dict['1'].keys()):\n",
    "    print key\n",
    "    summ += probe_dict['1'][key].shape[0]\n",
    "    print probe_dict['1'][key].shape\n",
    "print summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the keys in our dict:  ['CLOCK', 'JUICE', 'BRICK', 'PANTS', 'GLASS'] \n",
      "\n",
      "Shape for Probeword:  CLOCK   (227, 672)\n",
      "Shape for Probeword:  JUICE   (242, 672)\n",
      "Shape for Probeword:  BRICK   (358, 672)\n",
      "Shape for Probeword:  PANTS   (243, 672)\n",
      "Shape for Probeword:  GLASS   (361, 672)\n",
      "This is the shape of our new feature matrix for a certain word pair match: \n",
      "(227, 672)\n"
     ]
    }
   ],
   "source": [
    "### Concatenate a dict of all feature match/pairs\n",
    "match_features = dict.fromkeys(probe_dict['1'].keys())\n",
    "for key in match_features.keys():\n",
    "    match_features[key] = []\n",
    "print \"These are the keys in our dict: \", match_features.keys(), \"\\n\"\n",
    "    \n",
    "# loop through each probe_dict keys (channel)\n",
    "channels = probe_dict.keys()\n",
    "for idx, chan in enumerate(channels):\n",
    "    probe_channel = probe_dict[chan] # get the specific feature for that channel\n",
    "    \n",
    "    # loop through each match pair\n",
    "    probes = probe_channel.keys()\n",
    "    for probe in probes:\n",
    "        # get feature for this match/pair\n",
    "        feature = probe_channel[probe]\n",
    "        \n",
    "        if idx==0:\n",
    "            match_features[probe] = feature\n",
    "            match_features[probe] = np.array(match_features[probe])\n",
    "        else:\n",
    "            match_features[probe] = np.append(match_features[probe],feature,axis=1)   \n",
    "        \n",
    "# convert everything into np arrays\n",
    "for key in match_features.keys():\n",
    "    match_features[key] = np.array(match_features[key])\n",
    "    print \"Shape for Probeword: \", key, \" \", match_features[key].shape\n",
    "\n",
    "print \"This is the shape of our new feature matrix for a certain word pair match: \"\n",
    "print match_features[pair].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Matrices For Each Probe Word\n",
    "For each probe word, there are now #events X #features for each match. We will use that to create a classification testing protocol for each probeword. \n",
    "\n",
    "First we will begin with a binary classification between different word pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['CLOCK', 'JUICE'], ['CLOCK', 'BRICK'], ['CLOCK', 'PANTS'], ['CLOCK', 'GLASS'], ['JUICE', 'BRICK'], ['JUICE', 'PANTS'], ['JUICE', 'GLASS'], ['BRICK', 'PANTS'], ['BRICK', 'GLASS'], ['PANTS', 'GLASS']]\n"
     ]
    }
   ],
   "source": [
    "comb = sum([map(list, itertools.combinations(match_features.keys(), 2))], [])\n",
    "print comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 6, 2)\n",
      "('Accuracy for pair: ', ['CLOCK', 'JUICE'])\n",
      "Accuracy of Nearest Neighbors: 0.52 (+/- 1.00)\n",
      "Accuracy of Linear SVM: 0.41 (+/- 0.98)\n",
      "Accuracy of Random Forest: 0.52 (+/- 1.00)\n",
      "Accuracy of Linear Discriminant Analysis: 0.46 (+/- 1.00)\n",
      "Accuracy of Quadratic Discriminant Analysis: 0.45 (+/- 1.00)\n",
      "Accuracy of Logistic Regression: 0.42 (+/- 0.99)\n",
      "('Accuracy for pair: ', ['CLOCK', 'BRICK'])\n",
      "Accuracy of Nearest Neighbors: 0.48 (+/- 1.00)\n",
      "Accuracy of Linear SVM: 0.53 (+/- 1.00)\n",
      "Accuracy of Random Forest: 0.61 (+/- 0.98)\n",
      "Accuracy of Linear Discriminant Analysis: 0.46 (+/- 1.00)\n",
      "Accuracy of Quadratic Discriminant Analysis: 0.51 (+/- 1.00)\n",
      "Accuracy of Logistic Regression: 0.51 (+/- 1.00)\n",
      "('Accuracy for pair: ', ['CLOCK', 'PANTS'])\n",
      "Accuracy of Nearest Neighbors: 0.53 (+/- 1.00)\n",
      "Accuracy of Linear SVM: 0.46 (+/- 1.00)\n",
      "Accuracy of Random Forest: 0.54 (+/- 1.00)\n",
      "Accuracy of Linear Discriminant Analysis: 0.50 (+/- 1.00)\n",
      "Accuracy of Quadratic Discriminant Analysis: 0.47 (+/- 1.00)\n",
      "Accuracy of Logistic Regression: 0.45 (+/- 0.99)\n",
      "('Accuracy for pair: ', ['CLOCK', 'GLASS'])\n",
      "Accuracy of Nearest Neighbors: 0.56 (+/- 0.99)\n",
      "Accuracy of Linear SVM: 0.53 (+/- 1.00)\n",
      "Accuracy of Random Forest: 0.62 (+/- 0.97)\n",
      "Accuracy of Linear Discriminant Analysis: 0.54 (+/- 1.00)\n",
      "Accuracy of Quadratic Discriminant Analysis: 0.52 (+/- 1.00)\n",
      "Accuracy of Logistic Regression: 0.53 (+/- 1.00)\n",
      "('Accuracy for pair: ', ['JUICE', 'BRICK'])\n",
      "Accuracy of Nearest Neighbors: 0.51 (+/- 1.00)\n",
      "Accuracy of Linear SVM: 0.47 (+/- 1.00)\n",
      "Accuracy of Random Forest: 0.55 (+/- 1.00)\n",
      "Accuracy of Linear Discriminant Analysis: 0.50 (+/- 1.00)\n",
      "Accuracy of Quadratic Discriminant Analysis: 0.54 (+/- 1.00)\n",
      "Accuracy of Logistic Regression: 0.48 (+/- 1.00)\n",
      "('Accuracy for pair: ', ['JUICE', 'PANTS'])\n",
      "Accuracy of Nearest Neighbors: 0.51 (+/- 1.00)\n",
      "Accuracy of Linear SVM: 0.48 (+/- 1.00)\n",
      "Accuracy of Random Forest: 0.51 (+/- 1.00)\n",
      "Accuracy of Linear Discriminant Analysis: 0.47 (+/- 1.00)\n",
      "Accuracy of Quadratic Discriminant Analysis: 0.50 (+/- 1.00)\n",
      "Accuracy of Logistic Regression: 0.50 (+/- 1.00)\n",
      "('Accuracy for pair: ', ['JUICE', 'GLASS'])\n",
      "Accuracy of Nearest Neighbors: 0.57 (+/- 0.99)\n",
      "Accuracy of Linear SVM: 0.53 (+/- 1.00)\n",
      "Accuracy of Random Forest: 0.59 (+/- 0.99)\n",
      "Accuracy of Linear Discriminant Analysis: 0.46 (+/- 1.00)\n",
      "Accuracy of Quadratic Discriminant Analysis: 0.49 (+/- 1.00)\n",
      "Accuracy of Logistic Regression: 0.52 (+/- 1.00)\n",
      "('Accuracy for pair: ', ['BRICK', 'PANTS'])\n",
      "Accuracy of Nearest Neighbors: 0.50 (+/- 1.00)\n",
      "Accuracy of Linear SVM: 0.49 (+/- 1.00)\n",
      "Accuracy of Random Forest: 0.56 (+/- 0.99)\n",
      "Accuracy of Linear Discriminant Analysis: 0.47 (+/- 1.00)\n",
      "Accuracy of Quadratic Discriminant Analysis: 0.49 (+/- 1.00)\n",
      "Accuracy of Logistic Regression: 0.48 (+/- 1.00)\n",
      "('Accuracy for pair: ', ['BRICK', 'GLASS'])\n",
      "Accuracy of Nearest Neighbors: 0.50 (+/- 1.00)\n",
      "Accuracy of Linear SVM: 0.48 (+/- 1.00)\n",
      "Accuracy of Random Forest: 0.51 (+/- 1.00)\n",
      "Accuracy of Linear Discriminant Analysis: 0.49 (+/- 1.00)\n",
      "Accuracy of Quadratic Discriminant Analysis: 0.48 (+/- 1.00)\n",
      "Accuracy of Logistic Regression: 0.48 (+/- 1.00)\n",
      "('Accuracy for pair: ', ['PANTS', 'GLASS'])\n",
      "Accuracy of Nearest Neighbors: 0.57 (+/- 0.99)\n",
      "Accuracy of Linear SVM: 0.50 (+/- 1.00)\n",
      "Accuracy of Random Forest: 0.57 (+/- 0.99)\n",
      "Accuracy of Linear Discriminant Analysis: 0.48 (+/- 1.00)\n",
      "Accuracy of Quadratic Discriminant Analysis: 0.51 (+/- 1.00)\n",
      "Accuracy of Logistic Regression: 0.52 (+/- 1.00)\n"
     ]
    }
   ],
   "source": [
    "accuracy=np.zeros((len(comb),len(classifiers),2))\n",
    "print accuracy.shape\n",
    "for i,pair in enumerate(comb): \n",
    "    # Create classes and feature vects\n",
    "    firstprobe = match_features[pair[0]]\n",
    "    secondprobe = match_features[pair[1]]\n",
    "    features = np.append(firstprobe, secondprobe, axis=0)\n",
    "    y = np.ones((firstprobe.shape[0],))\n",
    "    y = np.concatenate((y, np.zeros((secondprobe.shape[0],))))\n",
    "    \n",
    "    print(\"Accuracy for pair: \", pair)\n",
    "    for idx, cla in enumerate(classifiers):\n",
    "        X_train, X_test, y_train, y_test = cross_validation.train_test_split(features, y, test_size=0.4, random_state=0)\n",
    "\n",
    "        clf = cla.fit(X_train, y_train)\n",
    "        loo = LeaveOneOut(len(features))\n",
    "        scores = cross_validation.cross_val_score(clf, features, y, cv=loo)\n",
    "        accuracy[i,idx,] = [scores.mean(), scores.std()]\n",
    "#         print(\"Accuracy of %s: %0.2f (+/- %0.2f)\" % (names[idx], scores.mean(), scores.std() * 2))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Analysis With 12 Unique Match Pairs\n",
    "We see here that all of our classifiers essentially performed as well as chance. Therefore we need to segment our data further. \n",
    "\n",
    "Instead of looking at solely probe words, now I look at unique match pairs (e.g. brick-juice vs. brick-pants)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final feature dictionary will have features\n",
      "from the following channels:  ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96']\n"
     ]
    }
   ],
   "source": [
    "################## LOOPING THROUGH EACH CHANNEL ##################\n",
    "feature_dict = {} # the dict to hold the feature matrix for each channel\n",
    "\n",
    "for f in range(0, len(files)):\n",
    "    ############### Set up data from the channel's mat file ##############\n",
    "    # Go through each .mat file\n",
    "    mat_file = filedir + files[f]\n",
    "\n",
    "    data = scipy.io.loadmat(mat_file)\n",
    "    data = data['data']\n",
    "\n",
    "\n",
    "    ## 01: reformat unique trigger types\n",
    "    uniqueTrigTypes = data['uniqueTrigType'][0][0][0]\n",
    "    buff = []\n",
    "    for trig in uniqueTrigTypes:\n",
    "        buff.append(str(trig[0]))\n",
    "    uniqueTrigTypes = buff\n",
    "\n",
    "    ## 02: reformat trigger types\n",
    "    trigTypes = data['trigType'][0][0][0]\n",
    "    buff = []\n",
    "    for trig in trigTypes:\n",
    "        buff.append(str(trig[0]))\n",
    "    trigTypes = buff\n",
    "\n",
    "    ## 03: get channel number\n",
    "    chanNum = data['chanNum'][0][0][0][0]\n",
    "\n",
    "    ## 04: get channel string\n",
    "    chanStr = data['chanStr'][0][0][0]\n",
    "\n",
    "    ## 05: get power matrix Z is a #events X #freq. bands\n",
    "    matrix = data['powerMatZ'][0][0]\n",
    "\n",
    "    ## 06: get freq band ticks and ylabels\n",
    "    freqBandYtick = data['freqBandYtick'][0][0][0]\n",
    "    freqBandYlabel = data['freqBandYlabel'][0][0][0]\n",
    "    buff = []\n",
    "    for freq in freqBandYlabel:\n",
    "        buff.append(str(freq[0]))\n",
    "    freqBandYlabel = buff\n",
    "\n",
    "    ################ Getting those events and the corresonding averaged powermat  #############\n",
    "    ## Get events of interest\n",
    "    TRIGGER_TYPES = uniqueTrigTypes\n",
    "    probeWords = events['probeWord']\n",
    "    targetWords = events['targetWord']\n",
    "\n",
    "    # number of frequency bins\n",
    "    num_freqs = len(freqBandYtick) - 1\n",
    "    # total number of \"data centers\"\n",
    "#     num_features = len(TRIGGER_TYPES)*len(tempTargets)\n",
    "    features = {}\n",
    "    \n",
    "    for i in range(0,len(TRIGGER_TYPES)): # LOOP THRU EACH PROBEWORD\n",
    "        current_trig = TRIGGER_TYPES[i]\n",
    "\n",
    "        ## 01: get indices of the current trigger and get those events\n",
    "        tempInd = events['probeWord'] == current_trig\n",
    "        tempEvents = events[tempInd]\n",
    "        tempTargets = np.unique(tempEvents['targetWord'])\n",
    "    \n",
    "        ## 02: go through each target word for this probeword\n",
    "        for j in range(0, len(tempTargets)):\n",
    "            targetWord = tempTargets[j][0] # set target word\n",
    "    \n",
    "            # get the indices of the events we want probe/target match\n",
    "            eventInd = events['probeWord'] == current_trig\n",
    "            eventInd2 = events['targetWord'] == targetWord\n",
    "            eventInd = eventInd & eventInd2\n",
    "\n",
    "            # get the matrix we want and average across all events \n",
    "#             thisMat = np.mean(matrix[eventInd,:], axis=0)\n",
    "            # -> a 7x1 vector that represents this match for this channel \n",
    "            \n",
    "            thisMat = matrix[eventInd,:]\n",
    "        \n",
    "            feature_key = str(current_trig) + '_' + str(targetWord)\n",
    "            \n",
    "            features[feature_key] = thisMat\n",
    "            # clear vars\n",
    "            eventInd2 = 0\n",
    "    \n",
    "    # turn features into np array and append to a dict of the features\n",
    "#     features = np.array(features)\n",
    "    feature_dict[str(f+1)] = features\n",
    "\n",
    "print \"The final feature dictionary will have features\"\n",
    "print \"from the following channels: \", sorted(feature_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summ = 0\n",
    "# for key in sorted(feature_dict['1'].keys()):\n",
    "#     print key\n",
    "#     summ += feature_dict['1'][key].shape[0]\n",
    "#     print feature_dict['1'][key].shape\n",
    "# print summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the keys in our dict:  ['JUICE_GLASS', 'BRICK_JUICE', 'CLOCK_GLASS', 'GLASS_CLOCK', 'GLASS_JUICE', 'BRICK_CLOCK', 'GLASS_PANTS', 'PANTS_BRICK', 'PANTS_GLASS', 'JUICE_BRICK', 'BRICK_PANTS', 'CLOCK_BRICK'] \n",
      "\n",
      "Shape for Probeword:  JUICE_GLASS   (115, 672)\n",
      "Shape for Probeword:  BRICK_JUICE   (126, 672)\n",
      "Shape for Probeword:  CLOCK_GLASS   (115, 672)\n",
      "Shape for Probeword:  GLASS_CLOCK   (118, 672)\n",
      "Shape for Probeword:  GLASS_JUICE   (114, 672)\n",
      "Shape for Probeword:  BRICK_CLOCK   (114, 672)\n",
      "Shape for Probeword:  GLASS_PANTS   (129, 672)\n",
      "Shape for Probeword:  PANTS_BRICK   (117, 672)\n",
      "Shape for Probeword:  PANTS_GLASS   (126, 672)\n",
      "Shape for Probeword:  JUICE_BRICK   (127, 672)\n",
      "Shape for Probeword:  BRICK_PANTS   (118, 672)\n",
      "Shape for Probeword:  CLOCK_BRICK   (112, 672)\n",
      "This is the shape of our new feature matrix for a certain word pair match: \n",
      "(115, 672)\n",
      "#events X (frequency vector X 96 channels)\n"
     ]
    }
   ],
   "source": [
    "### Concatenate a dict of all feature match/pairs\n",
    "match_features = dict.fromkeys(feature_dict['1'].keys())\n",
    "for key in match_features.keys():\n",
    "    match_features[key] = []\n",
    "print \"These are the keys in our dict: \", match_features.keys(), \"\\n\"\n",
    "    \n",
    "# loop through each probe_dict keys (channel)\n",
    "channels = feature_dict.keys()\n",
    "for idx, chan in enumerate(channels):\n",
    "    match_channel = feature_dict[chan] # get the specific feature for that channel\n",
    "    \n",
    "    # loop through each match pair\n",
    "    matches = match_channel.keys()\n",
    "    for match in matches:\n",
    "        # get feature for this match/pair\n",
    "        feature = match_channel[match]\n",
    "        \n",
    "        if idx==0:\n",
    "            match_features[match] = feature\n",
    "            match_features[match] = np.array(match_features[match])\n",
    "        else:\n",
    "            match_features[match] = np.append(match_features[match],feature,axis=1)   \n",
    "        \n",
    "# convert everything into np arrays\n",
    "for key in match_features.keys():\n",
    "    match_features[key] = np.array(match_features[key])\n",
    "    print \"Shape for Probeword: \", key, \" \", match_features[key].shape\n",
    "\n",
    "print \"This is the shape of our new feature matrix for a certain word pair match: \"\n",
    "print match_features['JUICE_GLASS'].shape\n",
    "print \"#events X (frequency vector X 96 channels)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comb = sum([map(list, itertools.combinations(match_features.keys(), 2))], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 6, 2)\n",
      "('Accuracy for pair: ', ['JUICE_GLASS', 'BRICK_JUICE'])\n",
      "('Accuracy for pair: ', ['JUICE_GLASS', 'CLOCK_GLASS'])"
     ]
    }
   ],
   "source": [
    "accuracy=np.zeros((len(comb),len(classifiers),2))\n",
    "print accuracy.shape\n",
    "for i,pair in enumerate(comb): \n",
    "    # Create classes and feature vects\n",
    "    firstprobe = match_features[pair[0]]\n",
    "    secondprobe = match_features[pair[1]]\n",
    "    features = np.append(firstprobe, secondprobe, axis=0)\n",
    "    y = np.ones((firstprobe.shape[0],))\n",
    "    y = np.concatenate((y, np.zeros((secondprobe.shape[0],))))\n",
    "    \n",
    "    print(\"Accuracy for pair: \", pair)\n",
    "    for idx, cla in enumerate(classifiers):\n",
    "        X_train, X_test, y_train, y_test = cross_validation.train_test_split(features, y, test_size=0.4, random_state=0)\n",
    "\n",
    "        clf = cla.fit(X_train, y_train)\n",
    "        loo = LeaveOneOut(len(features))\n",
    "        scores = cross_validation.cross_val_score(clf, features, y, cv=loo)\n",
    "        accuracy[i,idx,] = [scores.mean(), scores.std()]\n",
    "#         print(\"Accuracy of %s: %0.2f (+/- %0.2f)\" % (names[idx], scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
